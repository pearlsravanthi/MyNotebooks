{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6682d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "#from scipy.misc import imread\n",
    "from imageio import imread\n",
    "import pickle as pickle\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7417782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor\n",
    "def extract_features(image_path, vector_size=32):\n",
    "    image = imread(image_path, pilmode=\"RGB\")\n",
    "    try:\n",
    "        # Using KAZE, cause SIFT, ORB and other was moved to additional module\n",
    "        # which is adding addtional pain during install\n",
    "        alg = cv2.KAZE_create()\n",
    "        # Dinding image keypoints\n",
    "        kps = alg.detect(image)\n",
    "        # Getting first 32 of them. \n",
    "        # Number of keypoints is varies depend on image size and color pallet\n",
    "        # Sorting them based on keypoint response value(bigger is better)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        # computing descriptors vector\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        # Flatten all of them in one big vector - our feature vector\n",
    "        dsc = dsc.flatten()\n",
    "        # Making descriptor of same size\n",
    "        # Descriptor vector size is 64\n",
    "        needed_size = (vector_size * 64)\n",
    "        if dsc.size < needed_size:\n",
    "            # if we have less the 32 descriptors then just adding zeros at the\n",
    "            # end of our feature vector\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print ('Error: ', e)\n",
    "        return None\n",
    "\n",
    "    return dsc\n",
    "\n",
    "\n",
    "def batch_extractor(images_path, pickled_db_path=\"all_features.pck\"):\n",
    "    print(images_path)\n",
    "    folders = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
    "    image_folders = folders[:-1]\n",
    "    image_files = []\n",
    "    for dir_path in image_folders:\n",
    "        image_files.append([os.path.join(dir_path, p) for p in sorted(os.listdir(dir_path))])\n",
    "\n",
    "    result = {}\n",
    "    for f in image_files:\n",
    "        print ('Extracting features from image %s' % f)\n",
    "        for image in f:\n",
    "            name = image.split('/')[-1].lower()\n",
    "            print('feature extraction, ', image, name)\n",
    "            result[name] = extract_features(image)\n",
    "    \n",
    "    # saving all our feature vectors in pickled file\n",
    "    with open(pickled_db_path, 'wb') as fp:\n",
    "        pickle.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import scipy\n",
    "#from scipy.misc import imread\n",
    "from imageio import imread\n",
    "\n",
    "def run():\n",
    "    images_path = 'C:/Users/User/Downloads/shell_dataset/dataset/train'\n",
    "    print(images_path)\n",
    "    folders = [os.path.join(images_path, p) for p in sorted(os.listdir(images_path))]\n",
    "    #print (folders[:-1])\n",
    "    image_folders = folders[:-1]\n",
    "    #print (type(image_folders))\n",
    "    image_files = []\n",
    "    for dir_path in image_folders:\n",
    "        image_files.append([os.path.join(dir_path, p) for p in sorted(os.listdir(dir_path))])\n",
    "#     print(len(image_files))\n",
    "    print(len(image_files[0]), image_files[0][0])#, image_files[0][54])\n",
    "#     print(image_files[0])\n",
    "    \n",
    "    \n",
    "    # getting 3 random images \n",
    "    sample = random.sample(image_files[0], 3)\n",
    "    \n",
    "    batch_extractor(images_path)\n",
    "    \n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
